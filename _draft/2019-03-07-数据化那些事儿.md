---
layout:     post
title:      "深度学习与计算机视觉-数据化那些事儿"
subtitle:   "2.数据化那些事儿"
date:       2019-03-06 12:40:00
author:     "魔峥"
header-img: "img/post-bg-2015.jpg"
catalog: true
mathjax: true

tags:
    - 深度学习与计算机视觉
    - 体系整理
---



# 数据化那些事儿



## 1 计算机表征数据方法
上一篇说过我们的目标是“**让计算机具有学习能力，计算机能够自己适应事先不可知事物的新输入**”。前人通过模拟人类的思考方式，想到了一种方法：可以将“不可知事物的输入”改换成“不可知事物数字特征的输入”，化不可运算数据为可运算数据。我们可以认为这是对“抽象能力”的模拟。首先，计算机的输入是高电频，低电频信号，转换为数字即为“0-1字符”。那就意味着我们必须把所有进入计算机计算的东西都“0-1”化。每个“0-1字符”一位，即为1bit。若干个再编为一组，直到你需要为止。例如图片存储是8bit编一组表示0-255，为一通道，3个通道组成颜色。为了表征事物而频繁地编组，解释了“计算机数据维数较多的本质原因”。

### 1.1 数据化
虽然电脑全用01来表示数据，但数据与数据大不相同。例如7摄氏度与8摄氏度可以数据化为7，8；第一街与第二街分别数据化为1，2；纸币面额10元，20元可以数字化为10，20。虽然都是已经变为数字，数字是可以相加，但是含义却有本质的不同。“7摄氏度+8摄氏度”还勉强能说出含义，但“第一街+第二街”是什么意思如果抛去实际含义，仅仅计算1+2=3，那么就变成“第一街+第二街=第三街”的笑话了。
我们必须为数据添加类型，如下表使用类型的方式限制输出。

| 类型 | 含义                                 |
| ---- | ------------------------------------ |
| 数值 | 具有实际测量意义，可以计算           |
| 类别 | 数值不能计算，没有数值意义，仅定性   |
| 时间 | 年月日：时分秒，特别常用这里单列     |
| 空间 | 地理位置信息，可以计算但不能简单计算 |
| 文本 | 文本信息（NLP相关）                  |
| 图片 | RGB三色信息                          |


说到这里，我们列举了很多实际事物数据化的方法。仔细观察好像与SQL数据库通用格式很像。的确，数据库软件的存在的最初目的就是对事物进行数据化存储。但在大数据数据时代，传统的关系型数据库已经不足以支持这么大规模的数据任务。关系型数据库转变成为了文件型数据库，文件型数据库对图片等非结构化数据库的存储有很大帮助。由于数据存储是个大工程，与本文无关，这里不多做阐述。

### 1.2 数据清洗
但实际生活中，我们接收到数据源可能会很差。在实际生产中，数据初选几乎是必须的作用。因为我们在收集数据时，经常会遇到格式的错误，长尾的冗余，重要项的缺失，等等。**所以接到数据的第一步，是将原始数据可视化，大致浏览下数据的内容**。 通过浏览可视化数据，我们可以发现数据文件中可识别的错误：包括检查数据一致性，处理无效值和缺失值等。

在面对错误，冗余，缺失等可判断因素的“脏”数据时，“数据清洗”可起到一定的效果。数据清洗是对数据质量保证的最后一关，最终目的是使数据集中的数据达成一致性。数据的质量很大部分决定了模型的上限。

1. **错误数据**很容易理解，但是数据错误是很难识别的一件事。例如一个数据：毛某某，小学生，年龄31岁。这类数据明显有问题，但是我们不好做出确切评论。

2. **冗余**表面上很好理解，例如我们在分析微博评论数据时，经常会遇到水军刷屏，这样的信息肯定是需要去除的。但是怎么判断那条是水军的回复呢？或者放大点说，怎么判断是长尾冗余言论呢？

3. **重要项缺失**表面上也好理解，就是重要特征缺失。例如做用户画像时，性别数据缺失。如果遇到次要数据（例如在做预测天气时，每条数据中的“气象台联系电话”这一选项缺失）我们可以直接在数据清洗这一过程就适当做一下数据挑选，直接把这一项去掉。重要不重要，待遇相差就这么大。。

   这里存在一个逻辑：在完全未知的情况下，你怎么知道缺失的项属于重要项？

   例如，当我们做人脸识别时，我们会需要一些原始图片数据。
   我们常常会收到奇怪的图片，例如这样：

   ![在这里插入图片描述](/img/mozheng/1-1.jpg)

   ![在这里插入图片描述](/img/mozheng/1-2.jpg) ![在这里插入图片描述](/img/mozheng/1-3.png)

   

   [emoji 无语]。。。。

   对于有人脸识别经验的人这样的数据质量真的不算太好。因为脸部肌肉挤压，很多脸部特征被掩盖。我们想要的图片是特征明显数据，例如是这样：

   ![在这里插入图片描述](/img/mozheng/1-4.jpg) ![在这里插入图片描述](/img/mozheng/1-5.jpg) ![在这里插入图片描述](/img/mozheng/1-6.jpeg)

   我们选后者，因为后面的数据轮廓更清晰，更有特征点。**这些东西外行是看不出来的，这也是比较要命的。**

这就是数据初选的意义。这么说来，人工干预的因素占很大比例。没错，做好数据筛选数据清洗，真的需要一定模型训练的经验。在业界广泛流传：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。个人认为这句话虽然些许夸大，但却说出了数据清洗的重要性。同时，这句话也引出了另一个重要概念：**特征选择与提取**”

### 1.3 再说数字化-特征选择提取
特征工程指的是把原始数据转变为模型的训练数据的过程，它的目的就是为了获取更好的训练数据特征。什么叫更好的特征？这个很有说法。在特征工程发展初期，特征选择与提取阶段往往依靠经验丰富的专家。这也衍生出一种程序系统叫“专家系统”。
特征选择是从特征中选出一个子集，而特征提取是从原始数据中构造出新的特征，的目的就是简化模型，

## 2 数据计算
为了解决建模问题，我们首先需要解决三个不确定的主观因素：

1. 数据化，如何将事物对象进行数据化？
2. 特征选择，事物数据化后可以直接用吗？
3. 计算方法，我们则那样建立数学模型？我们用什么样的方法计算参数？

在机器学习的初期，这三个问题必须由人工凭借自己的经验选择。有些人模型搭建得很好，参数精准，对新事物的评判比较好。当然，这三个不确定的主观因素往往导致模型搭建失败。

### 2.2.1 